{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87fd46e7-cb73-4bcf-ad3d-41e17de495bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdfplumber ‚úÖ Installed\n",
      "pandas ‚úÖ Installed\n",
      "numpy ‚úÖ Installed\n",
      "nltk ‚úÖ Installed\n",
      "WARNING:tensorflow:From C:\\Users\\singa\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "sentence_transformers ‚úÖ Installed\n",
      "sklearn ‚úÖ Installed\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "required_libraries = [\n",
    "    \"pdfplumber\", \"pandas\", \"numpy\", \"nltk\",\n",
    "    \"sentence_transformers\", \"sklearn\"\n",
    "]\n",
    "\n",
    "for lib in required_libraries:\n",
    "    try:\n",
    "        importlib.import_module(lib)\n",
    "        print(f\"{lib} ‚úÖ Installed\")\n",
    "    except ImportError:\n",
    "        print(f\"{lib} ‚ùå Not Installed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30714386-4a90-4b7c-9774-28a3b531ee73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\singa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "C:\\Users\\singa\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JobTitle</th>\n",
       "      <th>MatchScore</th>\n",
       "      <th>RequiredSkills</th>\n",
       "      <th>SkillGap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>0.470481</td>\n",
       "      <td>[python, sql, pandas, data visualization, mach...</td>\n",
       "      <td>[data visualization]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NLP Engineer</td>\n",
       "      <td>0.337800</td>\n",
       "      <td>[python, nlp, transformers, classification, te...</td>\n",
       "      <td>[text classification, named entity recognition...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>0.310052</td>\n",
       "      <td>[sql, excel, power bi, communication]</td>\n",
       "      <td>[power bi, excel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AI Researcher</td>\n",
       "      <td>0.295483</td>\n",
       "      <td>[python, deep learning, neural networks]</td>\n",
       "      <td>[neural networks]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>0.283514</td>\n",
       "      <td>[python, tensorflow, keras, deep learning]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    JobTitle  MatchScore  \\\n",
       "0             Data Scientist    0.470481   \n",
       "2               NLP Engineer    0.337800   \n",
       "3           Business Analyst    0.310052   \n",
       "4              AI Researcher    0.295483   \n",
       "1  Machine Learning Engineer    0.283514   \n",
       "\n",
       "                                      RequiredSkills  \\\n",
       "0  [python, sql, pandas, data visualization, mach...   \n",
       "2  [python, nlp, transformers, classification, te...   \n",
       "3              [sql, excel, power bi, communication]   \n",
       "4           [python, deep learning, neural networks]   \n",
       "1         [python, tensorflow, keras, deep learning]   \n",
       "\n",
       "                                            SkillGap  \n",
       "0                               [data visualization]  \n",
       "2  [text classification, named entity recognition...  \n",
       "3                                  [power bi, excel]  \n",
       "4                                  [neural networks]  \n",
       "1                                                 []  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Resume Analyzer & Job Matcher with Skill Suggestions using NLP in Jupyter Notebook\n",
    "\n",
    "# Step 1: Install required packages\n",
    "!pip install sentence-transformers pdfplumber pandas scikit-learn nltk\n",
    "\n",
    "# Step 2: Import libraries\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Step 3: Define utility functions\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        text = ''\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "def extract_skills(text, skill_list):\n",
    "    text = text.lower()\n",
    "    return [skill for skill in skill_list if skill in text]\n",
    "\n",
    "def load_job_data(csv_path):\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "def match_jobs(resume_text, job_df, model, top_n=5):\n",
    "    resume_embedding = model.encode(resume_text, convert_to_tensor=True)\n",
    "    job_embeddings = model.encode(job_df[\"JobDescription\"].tolist(), convert_to_tensor=True)\n",
    "    similarities = util.cos_sim(resume_embedding, job_embeddings)[0].cpu().numpy()\n",
    "    job_df[\"MatchScore\"] = similarities\n",
    "    return job_df.sort_values(\"MatchScore\", ascending=False).head(top_n)\n",
    "\n",
    "def detect_skill_gap(resume_skills, job_skills):\n",
    "    return set(job_skills) - set(resume_skills)\n",
    "\n",
    "def suggest_skills(top_jobs):\n",
    "    all_required = set(skill for skills in top_jobs[\"RequiredSkills\"] for skill in skills)\n",
    "    all_gaps = set(skill for gaps in top_jobs[\"SkillGap\"] for skill in gaps)\n",
    "    recommended = all_required.intersection(all_gaps)\n",
    "    return sorted(recommended)\n",
    "\n",
    "def run_resume_matcher(resume_pdf_path, job_csv_path, skill_list):\n",
    "    resume_text = extract_text_from_pdf(resume_pdf_path)\n",
    "    job_df = load_job_data(job_csv_path)\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    top_jobs = match_jobs(resume_text, job_df, model, top_n=5)\n",
    "    resume_skills = extract_skills(resume_text, skill_list)\n",
    "    top_jobs[\"RequiredSkills\"] = top_jobs[\"JobDescription\"].apply(lambda x: extract_skills(x, skill_list))\n",
    "    top_jobs[\"SkillGap\"] = top_jobs[\"RequiredSkills\"].apply(lambda x: list(detect_skill_gap(resume_skills, x)))\n",
    "\n",
    "    suggested_skills = suggest_skills(top_jobs)\n",
    "\n",
    "    return top_jobs[[\"JobTitle\", \"MatchScore\", \"RequiredSkills\", \"SkillGap\"]], suggested_skills\n",
    "\n",
    "# Step 4: Define a broad skill list for matching\n",
    "skills = [\n",
    "    'python', 'java', 'c++', 'sql', 'nosql', 'excel', 'tableau', 'power bi', 'pandas', 'numpy',\n",
    "    'matplotlib', 'seaborn', 'scikit-learn', 'tensorflow', 'keras', 'pytorch', 'nlp',\n",
    "    'natural language processing', 'transformers', 'huggingface', 'bert', 'gpt',\n",
    "    'data visualization', 'data preprocessing', 'data wrangling', 'data analysis',\n",
    "    'deep learning', 'machine learning', 'cloud computing', 'aws', 'azure', 'gcp',\n",
    "    'linux', 'git', 'docker', 'kubernetes', 'communication', 'teamwork', 'problem solving',\n",
    "    'critical thinking', 'neural networks', 'classification', 'regression',\n",
    "    'clustering', 'recommendation systems', 'text classification', 'named entity recognition',\n",
    "    'time series', 'feature engineering', 'statistical analysis', 'model evaluation'\n",
    "]\n",
    "\n",
    "# Step 5: Run the matcher with your actual files\n",
    "matched_jobs, recommended_skills = run_resume_matcher(\"resume.pdf\", \"job_descriptions.csv\", skills)\n",
    "\n",
    "print(\"\\nTop Matching Jobs:\\n\")\n",
    "display(matched_jobs)\n",
    "\n",
    "print(\"\\nüí° Suggested Skills to Learn (Skill Gap Across Top Jobs):\\n\")\n",
    "print(\", \".join(recommended_skills))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5030280f-19ca-495f-97f6-1ac8333c16ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
